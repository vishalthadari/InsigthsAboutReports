{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import openpyxl\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>CONAME</th>\n",
       "      <th>FYRMO</th>\n",
       "      <th>FDATE</th>\n",
       "      <th>FORM</th>\n",
       "      <th>SECFNAME</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199803</td>\n",
       "      <td>1998-03-06</td>\n",
       "      <td>10-K405</td>\n",
       "      <td>edgar/data/3662/0000950170-98-000413.txt</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199805</td>\n",
       "      <td>1998-05-15</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/3662/0000950170-98-001001.txt</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199808</td>\n",
       "      <td>1998-08-13</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-000783.txt</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-12</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002145.txt</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-16</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-001203.txt</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CIK            CONAME   FYRMO      FDATE     FORM  \\\n",
       "0  3662  SUNBEAM CORP/FL/  199803 1998-03-06  10-K405   \n",
       "1  3662  SUNBEAM CORP/FL/  199805 1998-05-15     10-Q   \n",
       "2  3662  SUNBEAM CORP/FL/  199808 1998-08-13  NT 10-Q   \n",
       "3  3662  SUNBEAM CORP/FL/  199811 1998-11-12   10-K/A   \n",
       "4  3662  SUNBEAM CORP/FL/  199811 1998-11-16  NT 10-Q   \n",
       "\n",
       "                                   SECFNAME  \\\n",
       "0  edgar/data/3662/0000950170-98-000413.txt   \n",
       "1  edgar/data/3662/0000950170-98-001001.txt   \n",
       "2  edgar/data/3662/0000950172-98-000783.txt   \n",
       "3  edgar/data/3662/0000950170-98-002145.txt   \n",
       "4  edgar/data/3662/0000950172-98-001203.txt   \n",
       "\n",
       "                                                link  \n",
       "0  https://www.sec.gov/Archives/edgar/data/3662/0...  \n",
       "1  https://www.sec.gov/Archives/edgar/data/3662/0...  \n",
       "2  https://www.sec.gov/Archives/edgar/data/3662/0...  \n",
       "3  https://www.sec.gov/Archives/edgar/data/3662/0...  \n",
       "4  https://www.sec.gov/Archives/edgar/data/3662/0...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_excel('cik_list.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('data')\n",
    "os.mkdir('data2')\n",
    "os.mkdir('stop_words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=['https://www3.nd.edu/~mcdonald/Data/ND_Stop_Words_Generic.txt','https://www3.nd.edu/~mcdonald/Data/ND_Stop_Words_Names.txt','https://www3.nd.edu/~mcdonald/Data/ND_Stop_Words_DatesandNumbers.txt','https://www3.nd.edu/~mcdonald/Data/ND_Stop_Words_Geographic.txt','https://www3.nd.edu/~mcdonald/Data/ND_Stop_Words_Currencies.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping stop words\n",
    "for i in range(len(links)):\n",
    "    f=requests.get(links[i],timeout=4)\n",
    "    sleep(1)\n",
    "    soup=BeautifulSoup(f.text,'html.parser')\n",
    "    f_obj=open('stop_words/stop_words_'+str(i)+'.txt',\"w+\")\n",
    "    lst=re.findall('\\w*[a-zA-Z]',soup.get_text().lower())\n",
    "    for j in lst:\n",
    "        f_obj.write(j+' ')\n",
    "    f_obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping webpages\n",
    "for i in range(len(data)):\n",
    "    f=requests.get(data['link'][i])\n",
    "    sleep(2.5)\n",
    "    text=f.text\n",
    "    f_obj=open('data/'+str(i)+'.txt','w+',encoding='utf-8')\n",
    "    f_obj.write(text)\n",
    "    f_obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking sentences present or not\n",
    "scores=[]\n",
    "for i in range(len(data)):\n",
    "    f_obj=open('data/'+str(i)+'.txt','r',encoding='utf-8')\n",
    "    text=f_obj.read()\n",
    "    f_obj.close()\n",
    "    soup=BeautifulSoup(text,'html.parser')\n",
    "    score=''\n",
    "    page_text=soup.get_text().lower()\n",
    "    if \"management's discussion and analysis\" in page_text:\n",
    "        score+='1'\n",
    "    if \"quantitative and qualitative disclosures about market risk\" in page_text:\n",
    "        score+='2'\n",
    "    if \"risk factors\" in page_text:\n",
    "        score+='3'\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    f_obj=open('data/'+str(i)+'.txt','r',encoding='utf-8')\n",
    "    text=f_obj.read().lower()\n",
    "    f_obj.close()\n",
    "    soup=BeautifulSoup(text,'html.parser')\n",
    "    if '1' in scores[i]:\n",
    "        text1=''\n",
    "        for elem in soup(text=re.compile(\"management's discussion and analysis\")):\n",
    "            text1=text1+' '+str(elem.parent)\n",
    "            f_obj1=open('data2/'+str(i)+'_text1.txt','w+',encoding='utf-8')\n",
    "            f_obj1.write(text1)\n",
    "            f_obj1.close()\n",
    "    if '2' in scores[i]:\n",
    "        text2=''\n",
    "        for elem in soup(text=re.compile(\"quantitative and qualitative disclosures about market risk\")):\n",
    "            text2=text2+' '+str(elem.parent)\n",
    "            f_obj1=open('data2/'+str(i)+'_text2.txt','w+',encoding='utf-8')\n",
    "            f_obj1.write(text2)\n",
    "            f_obj1.close()\n",
    "    if '3' in scores[i]:\n",
    "        text3=''\n",
    "        for elem in soup(text=re.compile(\"risk factors\")):\n",
    "            text3=text3+' '+str(elem.parent)\n",
    "            f_obj1=open('data2/'+str(i)+'_text3.txt','w+',encoding='utf-8')\n",
    "            f_obj1.write(text3)\n",
    "            f_obj1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Sequence Number</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Word Proportion</th>\n",
       "      <th>Average Proportion</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Doc Count</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Litigious</th>\n",
       "      <th>Constraining</th>\n",
       "      <th>Superfluous</th>\n",
       "      <th>Interesting</th>\n",
       "      <th>Modal</th>\n",
       "      <th>Irr_Verb</th>\n",
       "      <th>Harvard_IV</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AARDVARK</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>5.690194e-09</td>\n",
       "      <td>3.068740e-09</td>\n",
       "      <td>5.779943e-07</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AARDVARKS</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.404986e-10</td>\n",
       "      <td>8.217606e-12</td>\n",
       "      <td>7.841870e-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABACI</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5.619945e-10</td>\n",
       "      <td>1.686149e-10</td>\n",
       "      <td>7.096240e-08</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABACK</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3.512466e-10</td>\n",
       "      <td>1.727985e-10</td>\n",
       "      <td>7.532677e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABACUS</td>\n",
       "      <td>5</td>\n",
       "      <td>1752</td>\n",
       "      <td>1.230768e-07</td>\n",
       "      <td>1.198634e-07</td>\n",
       "      <td>1.110293e-05</td>\n",
       "      <td>465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word  Sequence Number  Word Count  Word Proportion  \\\n",
       "0   AARDVARK                1          81     5.690194e-09   \n",
       "1  AARDVARKS                2           2     1.404986e-10   \n",
       "2      ABACI                3           8     5.619945e-10   \n",
       "3      ABACK                4           5     3.512466e-10   \n",
       "4     ABACUS                5        1752     1.230768e-07   \n",
       "\n",
       "   Average Proportion       Std Dev  Doc Count  Negative  Positive  \\\n",
       "0        3.068740e-09  5.779943e-07         45         0         0   \n",
       "1        8.217606e-12  7.841870e-09          1         0         0   \n",
       "2        1.686149e-10  7.096240e-08          7         0         0   \n",
       "3        1.727985e-10  7.532677e-08          5         0         0   \n",
       "4        1.198634e-07  1.110293e-05        465         0         0   \n",
       "\n",
       "   Uncertainty  Litigious  Constraining  Superfluous  Interesting  Modal  \\\n",
       "0            0          0             0            0            0      0   \n",
       "1            0          0             0            0            0      0   \n",
       "2            0          0             0            0            0      0   \n",
       "3            0          0             0            0            0      0   \n",
       "4            0          0             0            0            0      0   \n",
       "\n",
       "   Irr_Verb  Harvard_IV  Syllables     Source  \n",
       "0         0           0          2  12of12inf  \n",
       "1         0           0          2  12of12inf  \n",
       "2         0           0          3  12of12inf  \n",
       "3         0           0          2  12of12inf  \n",
       "4         0           0          3  12of12inf  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_dict=pd.read_excel('Dict.xlsx')\n",
    "master_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a list of stop_words\n",
    "text=''\n",
    "for i in range(5):\n",
    "    f_obj=open('stop_words/stop_words_'+str(i)+'.txt',\"r\")\n",
    "    text+=f_obj.read()\n",
    "    f_obj.close()\n",
    "    text+=' '\n",
    "\n",
    "stop_words=re.findall('\\w*[a-zA-Z]',text)    #list of stop words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a list of positive and negative words from the dictionary\n",
    "positive_words=positive_words=list(master_dict[master_dict['Positive']>0]['Word'].apply(lambda f:f.lower()))\n",
    "negative_words=[]\n",
    "for i in master_dict[master_dict['Negative']>0]['Word']:\n",
    "    try:\n",
    "        negative_words.append(i.lower())\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_words=[]#list of number of words for each documnet\n",
    "words=[]#list of lists of cleaned words for each of the documents\n",
    "positive_words_docs=[]#list of lists of positive words for all the documents\n",
    "negative_words_docs=[]#list of lists of negative words for all the documents\n",
    "#lists of positive and negative scores for all the documents\n",
    "positive_scores=[]\n",
    "negative_scores=[]\n",
    "for i in range(len(data)):\n",
    "    try:\n",
    "        f_obj=open('data2/'+str(i)+'_text1.txt',\"r\",encoding='utf-8')\n",
    "        text=f_obj.read().lower()\n",
    "        f_obj.close()\n",
    "        soup=BeautifulSoup(text,'html.parser')\n",
    "        lst=re.findall('\\w*[a-zA-Z]',soup.get_text())#list of all the words for a document\n",
    "        lst_pos=[] #list of positive words for a document\n",
    "        lst_neg=[] #list of negative words for a document\n",
    "        lst_word=[]#list of words after cleaning i.e. after removing stop words\n",
    "        for j in lst:\n",
    "            if j not in stop_words:\n",
    "                lst_word.append(j)\n",
    "                if j in positive_words:\n",
    "                    lst_pos.append(j)\n",
    "                if j in negative_words:\n",
    "                    lst_neg.append(j)\n",
    "        positive_words_docs.append(lst_pos)\n",
    "        negative_words_docs.append(lst_pos)\n",
    "        positive_scores.append(len(lst_pos))\n",
    "        negative_scores.append(len(lst_neg))\n",
    "        words.append(lst_word)\n",
    "        number_of_words.append(len(lst_word))\n",
    "    \n",
    "    \n",
    "    except:\n",
    "        positive_words_docs.append(None)\n",
    "        negative_words_docs.append(None)\n",
    "        positive_scores.append(None)\n",
    "        negative_scores.append(None)\n",
    "        words.append(None)\n",
    "        number_of_words.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mda_positive_score']=positive_scores\n",
    "data['mda_negative_score']=negative_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#polarity_score\n",
    "polarity_scores=[]\n",
    "for i in range(len(data)):\n",
    "    try:\n",
    "        polarity_scores.append((positive_scores[i]-negative_scores[i])/(positive_scores[i]+negative_scores[i]+0.000001))\n",
    "    except:\n",
    "        polarity_scores.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mda_polarity_score']=polarity_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "sentences=[]#list of lists of sentences in a given document\n",
    "number_of_sentences=[]#list of number of sentencs in each of the document\n",
    "for i in range(len(data)):\n",
    "    try:\n",
    "        f_obj=open('data2/'+str(i)+'_text1.txt',\"r\",encoding='utf-8')\n",
    "        text=f_obj.read()\n",
    "        f_obj.close()\n",
    "        soup=BeautifulSoup(text,'html.parser')\n",
    "        lst_sentences=sent_tokenize(soup.get_text())\n",
    "        sentences.append(lst_sentences)\n",
    "        number_of_sentences.append(len(lst_sentences))\n",
    "    except:\n",
    "        sentences.append(None)\n",
    "        number_of_sentences.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_sentence_lengths=[]#average sentence lengths for mda section of each document\n",
    "for i in range(len(data)):\n",
    "    try:\n",
    "        average_sentence_lengths.append(number_of_words[i]/number_of_sentences[i])\n",
    "    except:\n",
    "        average_sentence_lengths.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mda_average_sentence_length']=average_sentence_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import cmudict\n",
    "d = cmudict.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nsyl(word):\n",
    "    try:\n",
    "        return [len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]][0]\n",
    "    except KeyError:\n",
    "        return syllables(word)\n",
    "\n",
    "def syllables(word):\n",
    "    count = 0\n",
    "    vowels = 'aeiouy'\n",
    "    word = word.lower()\n",
    "    if word[0] in vowels:\n",
    "        count +=1\n",
    "    for index in range(1,len(word)):\n",
    "        if word[index] in vowels and word[index-1] not in vowels:\n",
    "            count +=1\n",
    "    if word.endswith('e'):\n",
    "        count -= 1\n",
    "    if word.endswith('le'):\n",
    "        count+=1\n",
    "    if count == 0:\n",
    "        count +=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_cmplx_words=[]#list of percentages of complex words \n",
    "number_of_cmplx_words=[]#list of number of complex words \n",
    "for i in range(len(data)):\n",
    "    n_cmplx=0\n",
    "    try:\n",
    "        for j in words[i]:\n",
    "            if nsyl(j)>2:\n",
    "                n_cmplx+=1\n",
    "        percent_cmplx_words.append(n_cmplx*100/number_of_words[i])\n",
    "        number_of_cmplx_words.append(n_cmplx)\n",
    "    except:\n",
    "        n_cmplx=None\n",
    "        percent_cmplx_words.append(n_cmplx)\n",
    "        number_of_cmplx_words.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mda_percentage_of_complex_words']=percent_cmplx_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fog_indexes=[] #list of fog indexes for mda section\n",
    "for i in range(len(data)):\n",
    "    try:\n",
    "        fog_indexes.append(0.4*(percent_cmplx_words[i]+average_sentence_lengths[i]))\n",
    "    except:\n",
    "        fog_indexes.append(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mda_fog_index']=fog_indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mda_complex_word_count']=number_of_cmplx_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mda_word_count']=number_of_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncertain and constraining words\n",
    "constraining=pd.read_excel('constraining_dictionary.xlsx')\n",
    "uncertainty=pd.read_excel('uncertainty_dictionary.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertain_words=[x.lower() for x in uncertainty['Word']]\n",
    "constraining_words=[x.lower() for x in constraining['Word']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraining_words_docs=[] # constraining words for a given document\n",
    "constraining_score=[] # number of constraining words for a given document \n",
    "uncertain_words_docs=[] #uncertain words for a given document\n",
    "uncertainty_score=[] #number of uncertain words for a given document \n",
    "for i in range(len(data)):\n",
    "    lst_constraining=[]\n",
    "    lst_uncertainty=[]\n",
    "    try:\n",
    "        for j in words[i]:\n",
    "            if j in constraining_words:\n",
    "                lst_constraining.append(j)\n",
    "            if j in uncertain_words:\n",
    "                lst_uncertainty.append(j)\n",
    "        constraining_words_docs.append(lst_constraining)\n",
    "        constraining_score.append(len(lst_constraining))\n",
    "        uncertain_words_docs.append(lst_uncertainty)\n",
    "        uncertainty_score.append(len(lst_uncertainty))\n",
    "    except:\n",
    "        constraining_words_docs.append(None)\n",
    "        constraining_score.append(None)\n",
    "        uncertain_words_docs.append(None)\n",
    "        uncertainty_score.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mda_uncertainty_score']=uncertainty_score\n",
    "data['mda_constraining_score']=constraining_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_word_proportions=[]\n",
    "negative_word_proportions=[]\n",
    "constraining_word_proportions=[]\n",
    "uncertainty_word_proportions=[]\n",
    "for i in range(len(data)):\n",
    "    try:\n",
    "        positive_word_proportions.append(positive_scores[i]/number_of_words[i])\n",
    "        negative_word_proportions.append(negative_scores[i]/number_of_words[i])\n",
    "        constraining_word_proportions.append(constraining_score[i]/number_of_words[i])\n",
    "        uncertainty_word_proportions.append(uncertainty_score[i]/number_of_words[i])\n",
    "    except:\n",
    "        positive_word_proportions.append(None)\n",
    "        negative_word_proportions.append(None)\n",
    "        constraining_word_proportions.append(None)\n",
    "        uncertainty_word_proportions.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mda_positive_word_proportion']=positive_word_proportions\n",
    "data['mda_negative_word_proportion']=negative_word_proportions\n",
    "data['mda_constraining_word_proportion']=constraining_word_proportions\n",
    "data['mda_uncertainty_word_proportion']=uncertainty_word_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>CONAME</th>\n",
       "      <th>FYRMO</th>\n",
       "      <th>FDATE</th>\n",
       "      <th>FORM</th>\n",
       "      <th>SECFNAME</th>\n",
       "      <th>link</th>\n",
       "      <th>mda_positive_score</th>\n",
       "      <th>mda_negative_score</th>\n",
       "      <th>mda_polarity_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mda_percentage_of_complex_words</th>\n",
       "      <th>mda_fog_index</th>\n",
       "      <th>mda_complex_word_count</th>\n",
       "      <th>mda_word_count</th>\n",
       "      <th>mda_uncertainty_score</th>\n",
       "      <th>mda_constraining_score</th>\n",
       "      <th>mda_positive_word_proportion</th>\n",
       "      <th>mda_negative_word_proportion</th>\n",
       "      <th>mda_constraining_word_proportion</th>\n",
       "      <th>mda_uncertainty_word_proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199803</td>\n",
       "      <td>1998-03-06</td>\n",
       "      <td>10-K405</td>\n",
       "      <td>edgar/data/3662/0000950170-98-000413.txt</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "      <td>181.0</td>\n",
       "      <td>521.0</td>\n",
       "      <td>-0.484330</td>\n",
       "      <td>...</td>\n",
       "      <td>48.700332</td>\n",
       "      <td>None</td>\n",
       "      <td>8506.0</td>\n",
       "      <td>17466.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.010363</td>\n",
       "      <td>0.029829</td>\n",
       "      <td>0.010764</td>\n",
       "      <td>0.019867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199805</td>\n",
       "      <td>1998-05-15</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/3662/0000950170-98-001001.txt</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-0.728395</td>\n",
       "      <td>...</td>\n",
       "      <td>45.319905</td>\n",
       "      <td>None</td>\n",
       "      <td>765.0</td>\n",
       "      <td>1688.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.006517</td>\n",
       "      <td>0.041469</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.033768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199808</td>\n",
       "      <td>1998-08-13</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-000783.txt</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-12</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002145.txt</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "      <td>109.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>-0.647249</td>\n",
       "      <td>...</td>\n",
       "      <td>48.860459</td>\n",
       "      <td>None</td>\n",
       "      <td>5767.0</td>\n",
       "      <td>11803.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.009235</td>\n",
       "      <td>0.043125</td>\n",
       "      <td>0.014827</td>\n",
       "      <td>0.017284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-16</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-001203.txt</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    CIK            CONAME   FYRMO      FDATE     FORM  \\\n",
       "0  3662  SUNBEAM CORP/FL/  199803 1998-03-06  10-K405   \n",
       "1  3662  SUNBEAM CORP/FL/  199805 1998-05-15     10-Q   \n",
       "2  3662  SUNBEAM CORP/FL/  199808 1998-08-13  NT 10-Q   \n",
       "3  3662  SUNBEAM CORP/FL/  199811 1998-11-12   10-K/A   \n",
       "4  3662  SUNBEAM CORP/FL/  199811 1998-11-16  NT 10-Q   \n",
       "\n",
       "                                   SECFNAME  \\\n",
       "0  edgar/data/3662/0000950170-98-000413.txt   \n",
       "1  edgar/data/3662/0000950170-98-001001.txt   \n",
       "2  edgar/data/3662/0000950172-98-000783.txt   \n",
       "3  edgar/data/3662/0000950170-98-002145.txt   \n",
       "4  edgar/data/3662/0000950172-98-001203.txt   \n",
       "\n",
       "                                                link  mda_positive_score  \\\n",
       "0  https://www.sec.gov/Archives/edgar/data/3662/0...               181.0   \n",
       "1  https://www.sec.gov/Archives/edgar/data/3662/0...                11.0   \n",
       "2  https://www.sec.gov/Archives/edgar/data/3662/0...                 NaN   \n",
       "3  https://www.sec.gov/Archives/edgar/data/3662/0...               109.0   \n",
       "4  https://www.sec.gov/Archives/edgar/data/3662/0...                 NaN   \n",
       "\n",
       "   mda_negative_score  mda_polarity_score               ...                 \\\n",
       "0               521.0           -0.484330               ...                  \n",
       "1                70.0           -0.728395               ...                  \n",
       "2                 NaN                 NaN               ...                  \n",
       "3               509.0           -0.647249               ...                  \n",
       "4                 NaN                 NaN               ...                  \n",
       "\n",
       "  mda_percentage_of_complex_words  mda_fog_index mda_complex_word_count  \\\n",
       "0                       48.700332           None                 8506.0   \n",
       "1                       45.319905           None                  765.0   \n",
       "2                             NaN           None                    NaN   \n",
       "3                       48.860459           None                 5767.0   \n",
       "4                             NaN           None                    NaN   \n",
       "\n",
       "   mda_word_count  mda_uncertainty_score  mda_constraining_score  \\\n",
       "0         17466.0                  347.0                   188.0   \n",
       "1          1688.0                   57.0                     4.0   \n",
       "2             NaN                    NaN                     NaN   \n",
       "3         11803.0                  204.0                   175.0   \n",
       "4             NaN                    NaN                     NaN   \n",
       "\n",
       "   mda_positive_word_proportion  mda_negative_word_proportion  \\\n",
       "0                      0.010363                      0.029829   \n",
       "1                      0.006517                      0.041469   \n",
       "2                           NaN                           NaN   \n",
       "3                      0.009235                      0.043125   \n",
       "4                           NaN                           NaN   \n",
       "\n",
       "   mda_constraining_word_proportion  mda_uncertainty_word_proportion  \n",
       "0                          0.010764                         0.019867  \n",
       "1                          0.002370                         0.033768  \n",
       "2                               NaN                              NaN  \n",
       "3                          0.014827                         0.017284  \n",
       "4                               NaN                              NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data.to_excel('final_output.xlsx',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
